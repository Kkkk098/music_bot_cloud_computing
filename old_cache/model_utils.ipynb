{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f197e48a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_utils.py\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import librosa\n",
    "import os\n",
    "\n",
    "# Константы\n",
    "SAMPLE_RATE = 22050\n",
    "N_MFCC = 40\n",
    "N_MELS = 128\n",
    "HOP_LENGTH = 512\n",
    "DURATION = 30\n",
    "SUPPORTED_FORMATS = {'.mp3', '.wav', '.ogg'}\n",
    "MAX_FILE_SIZE = 20 * 1024 * 1024  # 20 MB\n",
    "\n",
    "# Определение устройства\n",
    "DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# Определение модели\n",
    "class Enhanced_CNN_RNN(nn.Module):\n",
    "    def __init__(self, n_classes):\n",
    "        super().__init__()\n",
    "        \n",
    "        # Улучшенная CNN часть\n",
    "        self.conv = nn.Sequential(\n",
    "            nn.Conv2d(1, 32, kernel_size=(3, 3), padding=1),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d((2, 2)),\n",
    "            nn.Dropout2d(0.25),\n",
    "            \n",
    "            nn.Conv2d(32, 64, kernel_size=(3, 3), padding=1),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d((2, 2)),\n",
    "            nn.Dropout2d(0.25),\n",
    "            \n",
    "            nn.Conv2d(64, 128, kernel_size=(3, 3), padding=1),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d((2, 2)),\n",
    "            nn.Dropout2d(0.25),\n",
    "            \n",
    "            nn.Conv2d(128, 256, kernel_size=(3, 3), padding=1),\n",
    "            nn.BatchNorm2d(256),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d((2, 2)),\n",
    "            nn.Dropout2d(0.25)\n",
    "        )\n",
    "        \n",
    "        # Автоматический расчет размера после сверточных слоев\n",
    "        with torch.no_grad():\n",
    "            # ОБНОВЛЕНО: теперь используем правильную высоту 193 вместо 168\n",
    "            dummy_input = torch.randn(1, 1, 193, 1300)  # (каналы, высота, ширина)\n",
    "            dummy_output = self.conv(dummy_input)\n",
    "            self.conv_output_channels = dummy_output.size(1)\n",
    "            self.conv_output_height = dummy_output.size(2)\n",
    "            self.conv_output_width = dummy_output.size(3)\n",
    "            \n",
    "            # Размер для GRU: каналы * высота\n",
    "            self.gru_input_size = self.conv_output_channels * self.conv_output_height\n",
    "            \n",
    "            print(f\"Автоматический расчет размеров:\")\n",
    "            print(f\"  Каналы после сверток: {self.conv_output_channels}\")\n",
    "            print(f\"  Высота после сверток: {self.conv_output_height}\")\n",
    "            print(f\"  Ширина после сверток: {self.conv_output_width}\")\n",
    "            print(f\"  Входной размер для GRU: {self.gru_input_size}\")\n",
    "        \n",
    "        # RNN часть с автоматическим расчетом размера входа\n",
    "        self.gru = nn.GRU(\n",
    "            input_size=self.gru_input_size,  # Используем автоматический расчет\n",
    "            hidden_size=256,\n",
    "            batch_first=True,\n",
    "            bidirectional=True,\n",
    "            num_layers=2,\n",
    "            dropout=0.3\n",
    "        )\n",
    "        \n",
    "        # Полносвязные слои\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(256 * 2, 128),  # Умножаем на 2 из-за bidirectional\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(128, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(64, n_classes)\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # CNN\n",
    "        x = self.conv(x)\n",
    "        \n",
    "        # Подготовка для RNN\n",
    "        batch_size, channels, height, width = x.size()\n",
    "        \n",
    "        # Проверка совместимости размеров\n",
    "        actual_gru_input_size = channels * height\n",
    "        if actual_gru_input_size != self.gru_input_size:\n",
    "            raise ValueError(f\"Несоответствие размеров: ожидалось {self.gru_input_size}, получено {actual_gru_input_size}\")\n",
    "        \n",
    "        # Переставляем размерности: (batch, time, channels, height)\n",
    "        x = x.permute(0, 3, 1, 2)\n",
    "        \n",
    "        # Объединяем каналы и высоту: (batch, time, channels * height)\n",
    "        x = x.contiguous().view(batch_size, width, channels * height)\n",
    "        \n",
    "        # RNN\n",
    "        out, _ = self.gru(x)\n",
    "        \n",
    "        # Берем последний выход\n",
    "        out = out[:, -1, :]\n",
    "        \n",
    "        # Fully connected\n",
    "        out = self.fc(out)\n",
    "        \n",
    "        return out\n",
    "\n",
    "# Функции обработки аудио\n",
    "def load_audio(path, sr=SAMPLE_RATE, duration=DURATION):\n",
    "    try:\n",
    "        y, _ = librosa.load(path, sr=sr, mono=True, duration=duration)\n",
    "        return y\n",
    "    except Exception as e:\n",
    "        print(f\"Ошибка загрузки файла {path}: {str(e)}\")\n",
    "        return np.zeros(sr * duration)\n",
    "\n",
    "def extract_enhanced_features(y, sr=SAMPLE_RATE, n_mfcc=N_MFCC, n_mels=N_MELS, hop_length=HOP_LENGTH):\n",
    "    # MFCC\n",
    "    mfcc = librosa.feature.mfcc(y=y, sr=sr, n_mfcc=n_mfcc, hop_length=hop_length)\n",
    "    \n",
    "    # Mel spectrogram\n",
    "    mel = librosa.feature.melspectrogram(y=y, sr=sr, n_mels=n_mels, hop_length=hop_length)\n",
    "    mel_db = librosa.power_to_db(mel)\n",
    "    \n",
    "    # Chroma features\n",
    "    chroma = librosa.feature.chroma_stft(y=y, sr=sr, hop_length=hop_length)\n",
    "    \n",
    "    # Spectral contrast\n",
    "    spectral_contrast = librosa.feature.spectral_contrast(y=y, sr=sr, hop_length=hop_length)\n",
    "    \n",
    "    # Tonnetz features\n",
    "    tonnetz = librosa.feature.tonnetz(y=y, sr=sr)\n",
    "    \n",
    "    # Stack features: shape (channels, time)\n",
    "    feat = np.vstack([mfcc, mel_db, chroma, spectral_contrast, tonnetz])\n",
    "    return feat.astype(np.float32)\n",
    "\n",
    "def predict_audio(file_path, model, label2idx, idx2label, device=DEVICE):\n",
    "    try:\n",
    "        y = load_audio(file_path)\n",
    "        features = extract_enhanced_features(y)\n",
    "        max_time = 800\n",
    "        if features.shape[1] < max_time:\n",
    "            pad_width = max_time - features.shape[1]\n",
    "            features = np.pad(features, ((0, 0), (0, pad_width)), mode='constant')\n",
    "        else:\n",
    "            features = features[:, :max_time]\n",
    "        features = (features - features.mean()) / (features.std() + 1e-6)\n",
    "        \n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            x = torch.tensor(features).unsqueeze(0).unsqueeze(0).to(device)\n",
    "            output = model(x)\n",
    "            probs = F.softmax(output, dim=1)\n",
    "            pred_idx = output.argmax(dim=1).item()\n",
    "            confidence = probs[0][pred_idx].item()\n",
    "            \n",
    "        return idx2label[pred_idx], confidence\n",
    "    except Exception as e:\n",
    "        raise RuntimeError(f\"Ошибка обработки аудио: {str(e)}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
